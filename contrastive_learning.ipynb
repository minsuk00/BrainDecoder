{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"\"\n",
    "dataset_path = os.path.join(root_path, \"dataset\")\n",
    "images_dataset_path = os.path.join(dataset_path, \"imageNet_images\")\n",
    "eeg_dataset_path = os.path.join(dataset_path, \"eeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, eeg_dataset_file_name=\"eeg_5_95_std.pth\") -> None:\n",
    "        super().__init__()\n",
    "        loaded = torch.load(os.path.join(eeg_dataset_path, eeg_dataset_file_name))\n",
    "        self.data = loaded[\"dataset\"]\n",
    "        self.labels = loaded[\"labels\"]\n",
    "        self.images = loaded[\"images\"]\n",
    "        self.size = len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # t() -> transpose\n",
    "        eeg = self.data[idx][\"eeg\"].t()\n",
    "        eeg = eeg[20:460, :]\n",
    "\n",
    "        label = self.data[idx][\"label\"]\n",
    "        return eeg, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Splitter(Dataset):\n",
    "    def __init__(self, dataset, split_name=\"train\") -> None:\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "        loaded = torch.load(\n",
    "            os.path.join(eeg_dataset_path, \"block_splits_by_image_all.pth\")\n",
    "        )\n",
    "        self.target_data_indices = loaded[\"splits\"][0][split_name]\n",
    "        # filter data that is too short\n",
    "        self.target_data_indices = [\n",
    "            i\n",
    "            for i in self.target_data_indices\n",
    "            if 450 <= self.dataset.data[i][\"eeg\"].size(1) <= 600\n",
    "        ]\n",
    "\n",
    "        self.size = len(self.target_data_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg, label = self.dataset[self.target_data_indices[idx]]\n",
    "        return eeg, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def get_item_eeg(self, anchor_label, positive: bool):\n",
    "        cnt = 0\n",
    "        while True:\n",
    "            idx = random.choice(self.target_data_indices)\n",
    "            if positive and self.dataset[idx][1] == anchor_label:\n",
    "                return self.dataset[idx][0]\n",
    "            if not positive and self.dataset[idx][1] != anchor_label:\n",
    "                return self.dataset[idx][0]\n",
    "\n",
    "            if cnt >= 100:\n",
    "                raise Exception(f\"get_item_eeg failed after {cnt} tries\")\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EEGDataset(eeg_dataset_file_name=\"eeg_5_95_std.pth\")\n",
    "loaders = {\n",
    "    split: DataLoader(\n",
    "        Splitter(dataset, split_name=split), batch_size=16, shuffle=True, drop_last=True\n",
    "    )\n",
    "    for split in [\"train\", \"val\", \"test\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor_ContrastiveLearning_NN(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        def dist_fn(x1, x2):\n",
    "            # TODO: dim=0??\n",
    "            return torch.sum(torch.pow(torch.subtract(x1, x2), 2), dim=0)\n",
    "\n",
    "        self.loss_fn = nn.TripletMarginWithDistanceLoss(\n",
    "            distance_function=dist_fn, margin=1.5\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        res = 0\n",
    "        return res\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # TODO: how to get a,p,n\n",
    "        # TODO: how to configure dataset?\n",
    "        anchor_indices = ()\n",
    "        positive_indices = ()\n",
    "        negative_indices = ()\n",
    "        anchor = self()\n",
    "        positive = self()\n",
    "        negative = self()\n",
    "\n",
    "        loss = self.loss_fn(anchor, positive, negative)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self):\n",
    "        anchor, positive, negative = self()\n",
    "        loss = self.loss_fn(anchor, positive, negative)\n",
    "        self.log(\"train_loss\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeatureExtractor_ContrastiveLearning_NN()\n",
    "\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=\"/Users/ms/cs/ML/NeuroImagen/lightning_logs/\",\n",
    "    name=\"test\",\n",
    "    version=None,\n",
    ")\n",
    "\n",
    "trainer = Trainer = L.Trainer(max_epochs=200, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloaders=loaders[\"train\"], val_dataloaders=[\"val\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroimagen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
