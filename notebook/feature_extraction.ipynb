{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lookup_dict import lookup_dict, id_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"\"\n",
    "dataset_path = os.path.join(root_path, \"dataset\")\n",
    "images_dataset_path = os.path.join(dataset_path, \"imageNet_images\")\n",
    "eeg_dataset_path = os.path.join(dataset_path, \"eeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset_1 (using custom dataset method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all image folders to create list of images\n",
    "\n",
    "import random\n",
    "\n",
    "dir_list = list(os.walk(images_dataset_path))\n",
    "# skip any unnecessary folders\n",
    "start_idx = len(dir_list) - 40\n",
    "images_list = []\n",
    "for sub_dir in dir_list[start_idx:]:\n",
    "    # images_list+=sub_dir[2]\n",
    "    images_list.extend(sub_dir[2])\n",
    "\n",
    "images_list = [image_name.replace(\".JPEG\", \"\") for image_name in images_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split images list to 8:1:1\n",
    "\n",
    "# random.shuffle(images_list)\n",
    "\n",
    "images_total_size = len(images_list)\n",
    "train_size = int(images_total_size * 0.8)\n",
    "val_size = int(images_total_size * 0.1)\n",
    "test_size = images_total_size - train_size - val_size\n",
    "\n",
    "train_images = images_list[:train_size]\n",
    "val_images = images_list[train_size : train_size + val_size]\n",
    "test_images = images_list[-1 * test_size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_dataset_name = \"eeg_5_95_std.pth\"\n",
    "eeg_dataset = torch.load(os.path.join(eeg_dataset_path, eeg_dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_list) -> None:\n",
    "        super().__init__()\n",
    "        self.x_data = []\n",
    "        self.y_data = []\n",
    "        # self.y_data = [image_name.split(\"_\")[0] for image_name in images_list]\n",
    "\n",
    "        for eeg_segment in eeg_dataset[\"dataset\"]:\n",
    "            for image_name in images_list:\n",
    "                if eeg_dataset[\"images\"][eeg_segment[\"image\"]] == image_name:\n",
    "                    self.x_data.append(eeg_segment[\"eeg\"][:, 20:460])\n",
    "                    # all_channel_list = np.array(eeg_segment['eeg'])\n",
    "                    # self.x_data.append(torch.from_numpy(all_channel_list[:,40:480]))\n",
    "                    # self.x_data.append(torch.FloatTensor([eeg_sequence[40:480] for eeg_sequence in eeg_segment['eeg']]))\n",
    "                    class_id = image_name.split(\"_\")[0]\n",
    "                    self.y_data.append(lookup_dict[class_id])\n",
    "                    # self.y_data.append(eeg_dataset['labels'][eeg_segment['label']])\n",
    "                    break\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_images)\n",
    "val_dataset = CustomDataset(val_images)\n",
    "test_dataset = CustomDataset(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset_2 (using splitter method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, eeg_dataset_file_name=\"eeg_5_95_std.pth\") -> None:\n",
    "        super().__init__()\n",
    "        loaded = torch.load(os.path.join(eeg_dataset_path, eeg_dataset_file_name))\n",
    "        self.data = loaded[\"dataset\"]\n",
    "        self.labels = loaded[\"labels\"]\n",
    "        self.images = loaded[\"images\"]\n",
    "        self.size = len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # t() -> transpose\n",
    "        eeg = self.data[idx][\"eeg\"].t()\n",
    "        eeg = eeg[20:460, :]\n",
    "\n",
    "        label = self.data[idx][\"label\"]\n",
    "        return eeg, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Splitter(Dataset):\n",
    "    def __init__(self, dataset, split_name=\"train\") -> None:\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "        loaded = torch.load(\n",
    "            os.path.join(eeg_dataset_path, \"block_splits_by_image_all.pth\")\n",
    "        )\n",
    "        self.target_data_indices = loaded[\"splits\"][0][split_name]\n",
    "        # filter data that is too short\n",
    "        self.target_data_indices = [\n",
    "            i\n",
    "            for i in self.target_data_indices\n",
    "            if 450 <= self.dataset.data[i][\"eeg\"].size(1) <= 600\n",
    "        ]\n",
    "\n",
    "        self.size = len(self.target_data_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg, label = self.dataset[self.target_data_indices[idx]]\n",
    "        return eeg, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EEGDataset(eeg_dataset_file_name=\"eeg_5_95_std.pth\")\n",
    "loaders = {\n",
    "    split: DataLoader(\n",
    "        Splitter(dataset, split_name=split), batch_size=16, shuffle=True, drop_last=True\n",
    "    )\n",
    "    for split in [\"train\", \"val\", \"test\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "seed = 1563423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with classifier attached\n",
    "class FeatureExtractorNN(L.LightningModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # seed_everything(seed,workers=True)\n",
    "\n",
    "        self.input_size = 128\n",
    "        self.hidden_size = 128\n",
    "        self.lstm_layers = 1\n",
    "        self.out_size = 128\n",
    "\n",
    "        # self.lstm = nn.LSTM(input_size=128,hidden_size=128,num_layers=128)\n",
    "        self.lstm = nn.LSTM(\n",
    "            self.input_size,\n",
    "            self.hidden_size,\n",
    "            num_layers=self.lstm_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(in_features=self.hidden_size, out_features=self.out_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.classifer = nn.Sequential(\n",
    "            nn.Linear(in_features=self.out_size, out_features=40),\n",
    "            # don't use softmax with cross entropy loss\n",
    "            # nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        # self.loss_fn = nn.NLLLoss()\n",
    "        self.training_step_outputs = {\"correct_num\": 0, \"loss_sum\": 0}\n",
    "        self.validation_step_outputs = {\"correct_num\": 0, \"loss_sum\": 0}\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        lstm_init = (\n",
    "            torch.zeros(self.lstm_layers, batch_size, self.hidden_size),\n",
    "            torch.zeros(self.lstm_layers, batch_size, self.hidden_size),\n",
    "        )\n",
    "        lstm_init = (lstm_init[0].to(device), lstm_init[0].to(device))\n",
    "\n",
    "        # dont need to transpose because already transposed when creating dataset\n",
    "        # input = input.transpose(1,2)\n",
    "\n",
    "        lstm_out, _ = self.lstm(input, lstm_init)\n",
    "        # tmp_out = lstm_out[:,-1,:] if input.dim()==3 else lstm_out[-1,:]\n",
    "        tmp_out = lstm_out[:, -1, :]\n",
    "        out = self.output(tmp_out)\n",
    "        # print(\"out shape\",out.shape)\n",
    "        res = self.classifer(out)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # return optim.SGD(self.parameters(),lr=1e-4,weight_decay=0.1)\n",
    "        # return optim.Adam(self.parameters(),lr=1e-3,weight_decay=0.1)\n",
    "        optimizer = optim.Adam(self.parameters(), lr=(1e-4) * 8, weight_decay=0.005)\n",
    "        # optimizer = optim.Adam(self.parameters(), lr=(1e-3))\n",
    "        # optimizer = optim.SGD(self.parameters(), lr=(1e-3), momentum=0.9)\n",
    "        # optimizer = optim.SGD(self.parameters(), lr=(1e-4) * 5)\n",
    "        self.scheduler = optim.lr_scheduler.LambdaLR(\n",
    "            optimizer, lambda epoch: 0.975**epoch\n",
    "        )\n",
    "        # self.scheduler = optim.lr_scheduler.CyclicLR(optimizer,base_lr=0.0001, max_lr=0.01,step_size_up=5,mode=\"triangular2\")\n",
    "        # self.scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "        # self.scheduler = optim.lr_scheduler.CyclicLR(\n",
    "        #     optimizer, base_lr=1e-6, max_lr=0.01, step_size_up=15, mode=\"triangular2\"\n",
    "        # )\n",
    "\n",
    "        return [optimizer], [self.scheduler]\n",
    "        # return [optimizer]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out, y)\n",
    "\n",
    "        self.log_dict({\"train_loss\": loss}, prog_bar=True, on_epoch=True)\n",
    "        preds = out.argmax(dim=1)\n",
    "        self.training_step_outputs[\"correct_num\"] += (preds == y).sum()\n",
    "        self.training_step_outputs[\"loss_sum\"] += loss\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        num_correct = self.training_step_outputs[\"correct_num\"]\n",
    "        acc = num_correct / loaders[\"train\"].dataset.__len__()\n",
    "        loss = self.training_step_outputs[\"loss_sum\"] / loaders[\"train\"].__len__()\n",
    "        print(\"\\n\")\n",
    "        # print(\"EPOCH:\",self.current_epoch)\n",
    "        print(\n",
    "            f\"Training accuracy: {acc.item()} ({num_correct.item()}/{loaders['train'].dataset.__len__()} correct)\"\n",
    "        )\n",
    "        print(\"Training loss (average):\", loss.item())\n",
    "        print(\"\\n\")\n",
    "        self.training_step_outputs[\"correct_num\"] = 0\n",
    "        self.training_step_outputs[\"loss_sum\"] = 0\n",
    "\n",
    "        print(\"Learning rate:\", self.scheduler.get_last_lr(), \"\\n\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out, y)\n",
    "\n",
    "        self.log_dict({\"val_loss\": loss}, prog_bar=True, on_epoch=True)\n",
    "        preds = out.argmax(dim=1)\n",
    "        self.validation_step_outputs[\"correct_num\"] += (preds == y).sum()\n",
    "        self.validation_step_outputs[\"loss_sum\"] += loss\n",
    "        # return loss\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        num_correct = self.validation_step_outputs[\"correct_num\"]\n",
    "        acc = num_correct / loaders[\"val\"].dataset.__len__()\n",
    "        loss = self.validation_step_outputs[\"loss_sum\"] / loaders[\"val\"].__len__()\n",
    "        print(\"\\n\")\n",
    "        # print(\"EPOCH:\",self.current_epoch)\n",
    "        print(\n",
    "            f\"Validation accuracy: {acc.item()} ({num_correct.item()}/{loaders['val'].dataset.__len__()} correct)\"\n",
    "        )\n",
    "        print(\"Validation loss (average):\", loss.item())\n",
    "        print(\"\\n\")\n",
    "        self.validation_step_outputs[\"correct_num\"] = 0\n",
    "        self.validation_step_outputs[\"loss_sum\"] = 0\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out, y)\n",
    "\n",
    "        y_hat = torch.argmax(out, dim=1)\n",
    "        # print(\"OUT,YHAT:\",out,y_hat)\n",
    "        test_acc = torch.sum(y == y_hat).item() / (len(y) * 1.0)\n",
    "\n",
    "        self.log_dict(\n",
    "            {\"test_loss\": loss, \"test_acc\": test_acc}, prog_bar=True, on_epoch=True\n",
    "        )\n",
    "        # print(\"   ||   test loss:\",loss.item(), \"   ||   test accuracy:\",test_acc )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 1563423\n",
    "\n",
    "# model = FeatureExtractorNN()\n",
    "# model.to(device)\n",
    "# trainer = L.Trainer()\n",
    "# # trainer.validate(model,dataloaders=val_loader)\n",
    "# trainer.validate(model, dataloaders=loaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 124/124 [00:02<00:00, 57.35it/s]\n",
      "\n",
      "Validation accuracy: 0.017051152884960175 (34/1994 correct)\n",
      "Validation loss (average): 3.694744348526001\n",
      "\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 124/124 [00:02<00:00, 56.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3.694744348526001     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.694744348526001    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | lstm      | LSTM             | 132 K \n",
      "1 | output    | Sequential       | 16.5 K\n",
      "2 | classifer | Sequential       | 5.2 K \n",
      "3 | loss_fn   | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "153 K     Trainable params\n",
      "0         Non-trainable params\n",
      "153 K     Total params\n",
      "0.615     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 76.04it/s]\n",
      "\n",
      "Validation accuracy: 0.0 (0/1994 correct)\n",
      "Validation loss (average): 0.05956156179308891\n",
      "\n",
      "\n",
      "Epoch 0: 100%|██████████| 497/497 [00:15<00:00, 31.18it/s, v_num=.005, train_loss_step=3.700]\n",
      "\n",
      "Validation accuracy: 0.020561685785651207 (41/1994 correct)\n",
      "Validation loss (average): 3.695744037628174\n",
      "\n",
      "\n",
      "Epoch 0: 100%|██████████| 497/497 [00:18<00:00, 27.32it/s, v_num=.005, train_loss_step=3.700, val_loss=3.700, train_loss_epoch=3.690]\n",
      "\n",
      "Training accuracy: 0.029400678351521492 (234/7959 correct)\n",
      "Training loss (average): 3.6855313777923584\n",
      "\n",
      "\n",
      "Learning rate: [0.00078] \n",
      "\n",
      "Epoch 1: 100%|██████████| 497/497 [00:14<00:00, 33.84it/s, v_num=.005, train_loss_step=3.700, val_loss=3.700, train_loss_epoch=3.690]\n",
      "\n",
      "Validation accuracy: 0.02206619828939438 (44/1994 correct)\n",
      "Validation loss (average): 3.699435234069824\n",
      "\n",
      "\n",
      "Epoch 1: 100%|██████████| 497/497 [00:16<00:00, 30.36it/s, v_num=.005, train_loss_step=3.700, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Training accuracy: 0.03103404864668846 (247/7959 correct)\n",
      "Training loss (average): 3.682142734527588\n",
      "\n",
      "\n",
      "Learning rate: [0.0007605] \n",
      "\n",
      "Epoch 2: 100%|██████████| 497/497 [00:14<00:00, 35.47it/s, v_num=.005, train_loss_step=3.660, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Validation accuracy: 0.019558675587177277 (39/1994 correct)\n",
      "Validation loss (average): 3.700610399246216\n",
      "\n",
      "\n",
      "Epoch 2: 100%|██████████| 497/497 [00:15<00:00, 31.96it/s, v_num=.005, train_loss_step=3.660, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Training accuracy: 0.03103404864668846 (247/7959 correct)\n",
      "Training loss (average): 3.6814358234405518\n",
      "\n",
      "\n",
      "Learning rate: [0.0007414874999999999] \n",
      "\n",
      "Epoch 3: 100%|██████████| 497/497 [00:14<00:00, 35.11it/s, v_num=.005, train_loss_step=3.660, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Validation accuracy: 0.02206619828939438 (44/1994 correct)\n",
      "Validation loss (average): 3.7013120651245117\n",
      "\n",
      "\n",
      "Epoch 3: 100%|██████████| 497/497 [00:15<00:00, 31.96it/s, v_num=.005, train_loss_step=3.660, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Training accuracy: 0.0337982140481472 (269/7959 correct)\n",
      "Training loss (average): 3.6790475845336914\n",
      "\n",
      "\n",
      "Learning rate: [0.0007229503124999999] \n",
      "\n",
      "Epoch 4: 100%|██████████| 497/497 [00:14<00:00, 35.47it/s, v_num=.005, train_loss_step=3.700, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Validation accuracy: 0.021564694121479988 (43/1994 correct)\n",
      "Validation loss (average): 3.7024784088134766\n",
      "\n",
      "\n",
      "Epoch 4: 100%|██████████| 497/497 [00:15<00:00, 31.32it/s, v_num=.005, train_loss_step=3.700, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Training accuracy: 0.03291870653629303 (262/7959 correct)\n",
      "Training loss (average): 3.6795010566711426\n",
      "\n",
      "\n",
      "Learning rate: [0.0007048765546874999] \n",
      "\n",
      "Epoch 5: 100%|██████████| 497/497 [00:14<00:00, 33.22it/s, v_num=.005, train_loss_step=3.680, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Validation accuracy: 0.021564694121479988 (43/1994 correct)\n",
      "Validation loss (average): 3.699070930480957\n",
      "\n",
      "\n",
      "Epoch 5: 100%|██████████| 497/497 [00:16<00:00, 29.89it/s, v_num=.005, train_loss_step=3.680, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Training accuracy: 0.033295638859272 (265/7959 correct)\n",
      "Training loss (average): 3.6787221431732178\n",
      "\n",
      "\n",
      "Learning rate: [0.0006872546408203125] \n",
      "\n",
      "Epoch 6: 100%|██████████| 497/497 [00:14<00:00, 33.94it/s, v_num=.005, train_loss_step=3.690, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Validation accuracy: 0.02507522515952587 (50/1994 correct)\n",
      "Validation loss (average): 3.6998112201690674\n",
      "\n",
      "\n",
      "Epoch 6: 100%|██████████| 497/497 [00:16<00:00, 30.40it/s, v_num=.005, train_loss_step=3.690, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Training accuracy: 0.033295638859272 (265/7959 correct)\n",
      "Training loss (average): 3.6780872344970703\n",
      "\n",
      "\n",
      "Learning rate: [0.0006700732747998046] \n",
      "\n",
      "Epoch 7: 100%|██████████| 497/497 [00:14<00:00, 33.54it/s, v_num=.005, train_loss_step=3.690, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Validation accuracy: 0.02407221682369709 (48/1994 correct)\n",
      "Validation loss (average): 3.6988961696624756\n",
      "\n",
      "\n",
      "Epoch 7: 100%|██████████| 497/497 [00:16<00:00, 30.06it/s, v_num=.005, train_loss_step=3.690, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Training accuracy: 0.03342128545045853 (266/7959 correct)\n",
      "Training loss (average): 3.675454616546631\n",
      "\n",
      "\n",
      "Learning rate: [0.0006533214429298095] \n",
      "\n",
      "Epoch 8: 100%|██████████| 497/497 [00:15<00:00, 33.13it/s, v_num=.005, train_loss_step=3.630, val_loss=3.700, train_loss_epoch=3.680]\n",
      "\n",
      "Validation accuracy: 0.029588766396045685 (59/1994 correct)\n",
      "Validation loss (average): 3.685258626937866\n",
      "\n",
      "\n",
      "Epoch 8: 100%|██████████| 497/497 [00:16<00:00, 29.67it/s, v_num=.005, train_loss_step=3.630, val_loss=3.690, train_loss_epoch=3.670]\n",
      "\n",
      "Training accuracy: 0.03467772156000137 (276/7959 correct)\n",
      "Training loss (average): 3.668983221054077\n",
      "\n",
      "\n",
      "Learning rate: [0.0006369884068565642] \n",
      "\n",
      "Epoch 9: 100%|██████████| 497/497 [00:14<00:00, 33.20it/s, v_num=.005, train_loss_step=3.660, val_loss=3.690, train_loss_epoch=3.670]\n",
      "\n",
      "Validation accuracy: 0.03610832616686821 (72/1994 correct)\n",
      "Validation loss (average): 3.6310102939605713\n",
      "\n",
      "\n",
      "Epoch 9: 100%|██████████| 497/497 [00:16<00:00, 29.70it/s, v_num=.005, train_loss_step=3.660, val_loss=3.630, train_loss_epoch=3.640]\n",
      "\n",
      "Training accuracy: 0.03894961625337601 (310/7959 correct)\n",
      "Training loss (average): 3.640233278274536\n",
      "\n",
      "\n",
      "Learning rate: [0.0006210636966851501] \n",
      "\n",
      "Epoch 10: 100%|██████████| 497/497 [00:15<00:00, 32.46it/s, v_num=.005, train_loss_step=3.630, val_loss=3.630, train_loss_epoch=3.640]\n",
      "\n",
      "Validation accuracy: 0.03410230576992035 (68/1994 correct)\n",
      "Validation loss (average): 3.5547127723693848\n",
      "\n",
      "\n",
      "Epoch 10: 100%|██████████| 497/497 [00:17<00:00, 28.97it/s, v_num=.005, train_loss_step=3.630, val_loss=3.550, train_loss_epoch=3.550]\n",
      "\n",
      "Training accuracy: 0.04183942824602127 (333/7959 correct)\n",
      "Training loss (average): 3.5526044368743896\n",
      "\n",
      "\n",
      "Learning rate: [0.0006055371042680214] \n",
      "\n",
      "Epoch 11: 100%|██████████| 497/497 [00:15<00:00, 32.21it/s, v_num=.005, train_loss_step=3.410, val_loss=3.550, train_loss_epoch=3.550]\n",
      "\n",
      "Validation accuracy: 0.043630894273519516 (87/1994 correct)\n",
      "Validation loss (average): 3.494158983230591\n",
      "\n",
      "\n",
      "Epoch 11: 100%|██████████| 497/497 [00:17<00:00, 28.94it/s, v_num=.005, train_loss_step=3.410, val_loss=3.490, train_loss_epoch=3.450]\n",
      "\n",
      "Training accuracy: 0.05113707855343819 (407/7959 correct)\n",
      "Training loss (average): 3.4494926929473877\n",
      "\n",
      "\n",
      "Learning rate: [0.0005903986766613207] \n",
      "\n",
      "Epoch 12: 100%|██████████| 497/497 [00:16<00:00, 31.05it/s, v_num=.005, train_loss_step=3.490, val_loss=3.490, train_loss_epoch=3.450]\n",
      "\n",
      "Validation accuracy: 0.04764292761683464 (95/1994 correct)\n",
      "Validation loss (average): 3.3915982246398926\n",
      "\n",
      "\n",
      "Epoch 12: 100%|██████████| 497/497 [00:18<00:00, 27.58it/s, v_num=.005, train_loss_step=3.490, val_loss=3.390, train_loss_epoch=3.390]\n",
      "\n",
      "Training accuracy: 0.04988063871860504 (397/7959 correct)\n",
      "Training loss (average): 3.392582654953003\n",
      "\n",
      "\n",
      "Learning rate: [0.0005756387097447877] \n",
      "\n",
      "Epoch 13: 100%|██████████| 497/497 [00:16<00:00, 29.41it/s, v_num=.005, train_loss_step=3.290, val_loss=3.390, train_loss_epoch=3.390]\n",
      "\n",
      "Validation accuracy: 0.04613841697573662 (92/1994 correct)\n",
      "Validation loss (average): 3.379329204559326\n",
      "\n",
      "\n",
      "Epoch 13: 100%|██████████| 497/497 [00:18<00:00, 26.43it/s, v_num=.005, train_loss_step=3.290, val_loss=3.380, train_loss_epoch=3.370]\n",
      "\n",
      "Training accuracy: 0.05515768378973007 (439/7959 correct)\n",
      "Training loss (average): 3.365008592605591\n",
      "\n",
      "\n",
      "Learning rate: [0.0005612477420011682] \n",
      "\n",
      "Epoch 14: 100%|██████████| 497/497 [00:16<00:00, 29.88it/s, v_num=.005, train_loss_step=3.260, val_loss=3.380, train_loss_epoch=3.370]\n",
      "\n",
      "Validation accuracy: 0.055667001754045486 (111/1994 correct)\n",
      "Validation loss (average): 3.3289742469787598\n",
      "\n",
      "\n",
      "Epoch 14: 100%|██████████| 497/497 [00:18<00:00, 26.77it/s, v_num=.005, train_loss_step=3.260, val_loss=3.330, train_loss_epoch=3.330]\n",
      "\n",
      "Training accuracy: 0.054403819143772125 (433/7959 correct)\n",
      "Training loss (average): 3.326875686645508\n",
      "\n",
      "\n",
      "Learning rate: [0.0005472165484511388] \n",
      "\n",
      "Epoch 15: 100%|██████████| 497/497 [00:16<00:00, 29.27it/s, v_num=.005, train_loss_step=3.600, val_loss=3.330, train_loss_epoch=3.330]\n",
      "\n",
      "Validation accuracy: 0.04513540491461754 (90/1994 correct)\n",
      "Validation loss (average): 3.4465763568878174\n",
      "\n",
      "\n",
      "Epoch 15: 100%|██████████| 497/497 [00:18<00:00, 26.34it/s, v_num=.005, train_loss_step=3.600, val_loss=3.450, train_loss_epoch=3.390]\n",
      "\n",
      "Training accuracy: 0.056916698813438416 (453/7959 correct)\n",
      "Training loss (average): 3.3897109031677246\n",
      "\n",
      "\n",
      "Learning rate: [0.0005335361347398604] \n",
      "\n",
      "Epoch 16: 100%|██████████| 497/497 [00:17<00:00, 28.32it/s, v_num=.005, train_loss_step=3.330, val_loss=3.450, train_loss_epoch=3.390]\n",
      "\n",
      "Validation accuracy: 0.03811434283852577 (76/1994 correct)\n",
      "Validation loss (average): 3.2876017093658447\n",
      "\n",
      "\n",
      "Epoch 16: 100%|██████████| 497/497 [00:19<00:00, 25.43it/s, v_num=.005, train_loss_step=3.330, val_loss=3.290, train_loss_epoch=3.290]\n",
      "\n",
      "Training accuracy: 0.06583741307258606 (524/7959 correct)\n",
      "Training loss (average): 3.289865016937256\n",
      "\n",
      "\n",
      "Learning rate: [0.0005201977313713639] \n",
      "\n",
      "Epoch 17: 100%|██████████| 497/497 [00:17<00:00, 28.26it/s, v_num=.005, train_loss_step=3.170, val_loss=3.290, train_loss_epoch=3.290]\n",
      "\n",
      "Validation accuracy: 0.0732196569442749 (146/1994 correct)\n",
      "Validation loss (average): 3.1269495487213135\n",
      "\n",
      "\n",
      "Epoch 17: 100%|██████████| 497/497 [00:19<00:00, 25.34it/s, v_num=.005, train_loss_step=3.170, val_loss=3.130, train_loss_epoch=3.170]\n",
      "\n",
      "Training accuracy: 0.07551199942827225 (601/7959 correct)\n",
      "Training loss (average): 3.170459747314453\n",
      "\n",
      "\n",
      "Learning rate: [0.0005071927880870797] \n",
      "\n",
      "Epoch 18: 100%|██████████| 497/497 [00:18<00:00, 26.44it/s, v_num=.005, train_loss_step=3.130, val_loss=3.130, train_loss_epoch=3.170]\n",
      "\n",
      "Validation accuracy: 0.08124373108148575 (162/1994 correct)\n",
      "Validation loss (average): 3.0292465686798096\n",
      "\n",
      "\n",
      "Epoch 18: 100%|██████████| 497/497 [00:20<00:00, 23.89it/s, v_num=.005, train_loss_step=3.130, val_loss=3.030, train_loss_epoch=3.060]\n",
      "\n",
      "Training accuracy: 0.0809146910905838 (644/7959 correct)\n",
      "Training loss (average): 3.057737350463867\n",
      "\n",
      "\n",
      "Learning rate: [0.0004945129683849027] \n",
      "\n",
      "Epoch 19: 100%|██████████| 497/497 [00:18<00:00, 26.95it/s, v_num=.005, train_loss_step=2.620, val_loss=3.030, train_loss_epoch=3.060]\n",
      "\n",
      "Validation accuracy: 0.09027080982923508 (180/1994 correct)\n",
      "Validation loss (average): 2.941769599914551\n",
      "\n",
      "\n",
      "Epoch 19: 100%|██████████| 497/497 [00:20<00:00, 24.26it/s, v_num=.005, train_loss_step=2.620, val_loss=2.940, train_loss_epoch=2.980]\n",
      "\n",
      "Training accuracy: 0.08832767605781555 (703/7959 correct)\n",
      "Training loss (average): 2.9814646244049072\n",
      "\n",
      "\n",
      "Learning rate: [0.00048215014417528015] \n",
      "\n",
      "Epoch 20: 100%|██████████| 497/497 [00:18<00:00, 26.51it/s, v_num=.005, train_loss_step=3.000, val_loss=2.940, train_loss_epoch=2.980]\n",
      "\n",
      "Validation accuracy: 0.07923771440982819 (158/1994 correct)\n",
      "Validation loss (average): 2.880922794342041\n",
      "\n",
      "\n",
      "Epoch 20: 100%|██████████| 497/497 [00:20<00:00, 23.82it/s, v_num=.005, train_loss_step=3.000, val_loss=2.880, train_loss_epoch=2.860]\n",
      "\n",
      "Training accuracy: 0.09963563084602356 (793/7959 correct)\n",
      "Training loss (average): 2.8587253093719482\n",
      "\n",
      "\n",
      "Learning rate: [0.00047009639057089814] \n",
      "\n",
      "Epoch 21: 100%|██████████| 497/497 [00:18<00:00, 26.89it/s, v_num=.005, train_loss_step=2.820, val_loss=2.880, train_loss_epoch=2.860]\n",
      "\n",
      "Validation accuracy: 0.0917753279209137 (183/1994 correct)\n",
      "Validation loss (average): 2.8255903720855713\n",
      "\n",
      "\n",
      "Epoch 21: 100%|██████████| 497/497 [00:20<00:00, 24.08it/s, v_num=.005, train_loss_step=2.820, val_loss=2.830, train_loss_epoch=2.790]\n",
      "\n",
      "Training accuracy: 0.10642040520906448 (847/7959 correct)\n",
      "Training loss (average): 2.7922451496124268\n",
      "\n",
      "\n",
      "Learning rate: [0.0004583439808066257] \n",
      "\n",
      "Epoch 22: 100%|██████████| 497/497 [00:19<00:00, 25.53it/s, v_num=.005, train_loss_step=2.670, val_loss=2.830, train_loss_epoch=2.790]\n",
      "\n",
      "Validation accuracy: 0.1043129414319992 (208/1994 correct)\n",
      "Validation loss (average): 2.768357992172241\n",
      "\n",
      "\n",
      "Epoch 22: 100%|██████████| 497/497 [00:21<00:00, 23.10it/s, v_num=.005, train_loss_step=2.670, val_loss=2.770, train_loss_epoch=2.760]\n",
      "\n",
      "Training accuracy: 0.11081793904304504 (882/7959 correct)\n",
      "Training loss (average): 2.7594358921051025\n",
      "\n",
      "\n",
      "Learning rate: [0.00044688538128646] \n",
      "\n",
      "Epoch 23: 100%|██████████| 497/497 [00:18<00:00, 26.86it/s, v_num=.005, train_loss_step=2.750, val_loss=2.770, train_loss_epoch=2.760]\n",
      "\n",
      "Validation accuracy: 0.09077231585979462 (181/1994 correct)\n",
      "Validation loss (average): 2.836923122406006\n",
      "\n",
      "\n",
      "Epoch 23: 100%|██████████| 497/497 [00:20<00:00, 24.23it/s, v_num=.005, train_loss_step=2.750, val_loss=2.840, train_loss_epoch=2.740]\n",
      "\n",
      "Training accuracy: 0.1157180517911911 (921/7959 correct)\n",
      "Training loss (average): 2.7415943145751953\n",
      "\n",
      "\n",
      "Learning rate: [0.0004357132467542985] \n",
      "\n",
      "Epoch 24: 100%|██████████| 497/497 [00:18<00:00, 26.68it/s, v_num=.005, train_loss_step=2.830, val_loss=2.840, train_loss_epoch=2.740]\n",
      "\n",
      "Validation accuracy: 0.10280842334032059 (205/1994 correct)\n",
      "Validation loss (average): 2.8894925117492676\n",
      "\n",
      "\n",
      "Epoch 24: 100%|██████████| 497/497 [00:20<00:00, 24.30it/s, v_num=.005, train_loss_step=2.830, val_loss=2.890, train_loss_epoch=2.680]\n",
      "\n",
      "Training accuracy: 0.12024123966693878 (957/7959 correct)\n",
      "Training loss (average): 2.6791484355926514\n",
      "\n",
      "\n",
      "Learning rate: [0.0004248204155854411] \n",
      "\n",
      "Epoch 25: 100%|██████████| 497/497 [00:19<00:00, 25.30it/s, v_num=.005, train_loss_step=2.770, val_loss=2.890, train_loss_epoch=2.680]\n",
      "\n",
      "Validation accuracy: 0.09528585523366928 (190/1994 correct)\n",
      "Validation loss (average): 2.8910512924194336\n",
      "\n",
      "\n",
      "Epoch 25: 100%|██████████| 497/497 [00:21<00:00, 22.92it/s, v_num=.005, train_loss_step=2.770, val_loss=2.890, train_loss_epoch=2.700]\n",
      "\n",
      "Training accuracy: 0.12413619458675385 (988/7959 correct)\n",
      "Training loss (average): 2.6997463703155518\n",
      "\n",
      "\n",
      "Learning rate: [0.000414199905195805] \n",
      "\n",
      "Epoch 26: 100%|██████████| 497/497 [00:19<00:00, 25.86it/s, v_num=.005, train_loss_step=2.580, val_loss=2.890, train_loss_epoch=2.700]\n",
      "\n",
      "Validation accuracy: 0.11133400350809097 (222/1994 correct)\n",
      "Validation loss (average): 2.6550633907318115\n",
      "\n",
      "\n",
      "Epoch 26: 100%|██████████| 497/497 [00:21<00:00, 23.24it/s, v_num=.005, train_loss_step=2.580, val_loss=2.660, train_loss_epoch=2.650]\n",
      "\n",
      "Training accuracy: 0.13167482614517212 (1048/7959 correct)\n",
      "Training loss (average): 2.6500704288482666\n",
      "\n",
      "\n",
      "Learning rate: [0.0004038449075659099] \n",
      "\n",
      "Epoch 27: 100%|██████████| 497/497 [00:19<00:00, 25.63it/s, v_num=.005, train_loss_step=2.340, val_loss=2.660, train_loss_epoch=2.650]\n",
      "\n",
      "Validation accuracy: 0.12988966703414917 (259/1994 correct)\n",
      "Validation loss (average): 2.57922625541687\n",
      "\n",
      "\n",
      "Epoch 27: 100%|██████████| 497/497 [00:21<00:00, 23.05it/s, v_num=.005, train_loss_step=2.340, val_loss=2.580, train_loss_epoch=2.590]\n",
      "\n",
      "Training accuracy: 0.1408468335866928 (1121/7959 correct)\n",
      "Training loss (average): 2.5884416103363037\n",
      "\n",
      "\n",
      "Learning rate: [0.00039374878487676213] \n",
      "\n",
      "Epoch 28: 100%|██████████| 497/497 [00:19<00:00, 25.61it/s, v_num=.005, train_loss_step=2.630, val_loss=2.580, train_loss_epoch=2.590]\n",
      "\n",
      "Validation accuracy: 0.1288866549730301 (257/1994 correct)\n",
      "Validation loss (average): 2.5533134937286377\n",
      "\n",
      "\n",
      "Epoch 28: 100%|██████████| 497/497 [00:21<00:00, 23.12it/s, v_num=.005, train_loss_step=2.630, val_loss=2.550, train_loss_epoch=2.550]\n",
      "\n",
      "Training accuracy: 0.14172634482383728 (1128/7959 correct)\n",
      "Training loss (average): 2.546611785888672\n",
      "\n",
      "\n",
      "Learning rate: [0.00038390506525484306] \n",
      "\n",
      "Epoch 29: 100%|██████████| 497/497 [00:19<00:00, 25.55it/s, v_num=.005, train_loss_step=2.600, val_loss=2.550, train_loss_epoch=2.550]\n",
      "\n",
      "Validation accuracy: 0.11685055494308472 (233/1994 correct)\n",
      "Validation loss (average): 2.5997579097747803\n",
      "\n",
      "\n",
      "Epoch 29: 100%|██████████| 497/497 [00:21<00:00, 22.92it/s, v_num=.005, train_loss_step=2.600, val_loss=2.600, train_loss_epoch=2.510]\n",
      "\n",
      "Training accuracy: 0.15228043496608734 (1212/7959 correct)\n",
      "Training loss (average): 2.514930009841919\n",
      "\n",
      "\n",
      "Learning rate: [0.00037430743862347195] \n",
      "\n",
      "Epoch 30: 100%|██████████| 497/497 [00:20<00:00, 23.98it/s, v_num=.005, train_loss_step=2.580, val_loss=2.600, train_loss_epoch=2.510]\n",
      "\n",
      "Validation accuracy: 0.1354062259197235 (270/1994 correct)\n",
      "Validation loss (average): 2.5739684104919434\n",
      "\n",
      "\n",
      "Epoch 30: 100%|██████████| 497/497 [00:22<00:00, 21.76it/s, v_num=.005, train_loss_step=2.580, val_loss=2.570, train_loss_epoch=2.540]\n",
      "\n",
      "Training accuracy: 0.14398793876171112 (1146/7959 correct)\n",
      "Training loss (average): 2.539137125015259\n",
      "\n",
      "\n",
      "Learning rate: [0.0003649497526578852] \n",
      "\n",
      "Epoch 31: 100%|██████████| 497/497 [00:21<00:00, 23.67it/s, v_num=.005, train_loss_step=2.380, val_loss=2.570, train_loss_epoch=2.540]\n",
      "\n",
      "Validation accuracy: 0.12838515639305115 (256/1994 correct)\n",
      "Validation loss (average): 2.553612232208252\n",
      "\n",
      "\n",
      "Epoch 31: 100%|██████████| 497/497 [00:23<00:00, 21.41it/s, v_num=.005, train_loss_step=2.380, val_loss=2.550, train_loss_epoch=2.470]\n",
      "\n",
      "Training accuracy: 0.15692926943302155 (1249/7959 correct)\n",
      "Training loss (average): 2.471968173980713\n",
      "\n",
      "\n",
      "Learning rate: [0.000355826008841438] \n",
      "\n",
      "Epoch 32: 100%|██████████| 497/497 [00:20<00:00, 24.18it/s, v_num=.005, train_loss_step=2.440, val_loss=2.550, train_loss_epoch=2.470]\n",
      "\n",
      "Validation accuracy: 0.14744232594966888 (294/1994 correct)\n",
      "Validation loss (average): 2.587275266647339\n",
      "\n",
      "\n",
      "Epoch 32: 100%|██████████| 497/497 [00:22<00:00, 21.83it/s, v_num=.005, train_loss_step=2.440, val_loss=2.590, train_loss_epoch=2.440]\n",
      "\n",
      "Training accuracy: 0.16296017169952393 (1297/7959 correct)\n",
      "Training loss (average): 2.438415765762329\n",
      "\n",
      "\n",
      "Learning rate: [0.00034693035862040205] \n",
      "\n",
      "Epoch 33: 100%|██████████| 497/497 [00:21<00:00, 22.73it/s, v_num=.005, train_loss_step=2.390, val_loss=2.590, train_loss_epoch=2.440]\n",
      "\n",
      "Validation accuracy: 0.1303911805152893 (260/1994 correct)\n",
      "Validation loss (average): 2.5308773517608643\n",
      "\n",
      "\n",
      "Epoch 33: 100%|██████████| 497/497 [00:24<00:00, 20.60it/s, v_num=.005, train_loss_step=2.390, val_loss=2.530, train_loss_epoch=2.440]\n",
      "\n",
      "Training accuracy: 0.16057293117046356 (1278/7959 correct)\n",
      "Training loss (average): 2.443533182144165\n",
      "\n",
      "\n",
      "Learning rate: [0.000338257099654892] \n",
      "\n",
      "Epoch 34: 100%|██████████| 497/497 [00:21<00:00, 22.99it/s, v_num=.005, train_loss_step=2.210, val_loss=2.530, train_loss_epoch=2.440]\n",
      "\n",
      "Validation accuracy: 0.14343029260635376 (286/1994 correct)\n",
      "Validation loss (average): 2.449631452560425\n",
      "\n",
      "\n",
      "Epoch 34: 100%|██████████| 497/497 [00:23<00:00, 20.85it/s, v_num=.005, train_loss_step=2.210, val_loss=2.450, train_loss_epoch=2.390]\n",
      "\n",
      "Training accuracy: 0.1771579384803772 (1410/7959 correct)\n",
      "Training loss (average): 2.389207601547241\n",
      "\n",
      "\n",
      "Learning rate: [0.0003298006721635197] \n",
      "\n",
      "Epoch 35: 100%|██████████| 497/497 [00:21<00:00, 22.88it/s, v_num=.005, train_loss_step=2.360, val_loss=2.450, train_loss_epoch=2.390]\n",
      "\n",
      "Validation accuracy: 0.13590772449970245 (271/1994 correct)\n",
      "Validation loss (average): 2.533890962600708\n",
      "\n",
      "\n",
      "Epoch 35: 100%|██████████| 497/497 [00:23<00:00, 20.74it/s, v_num=.005, train_loss_step=2.360, val_loss=2.530, train_loss_epoch=2.370]\n",
      "\n",
      "Training accuracy: 0.1813041865825653 (1443/7959 correct)\n",
      "Training loss (average): 2.3660337924957275\n",
      "\n",
      "\n",
      "Learning rate: [0.0003215556553594317] \n",
      "\n",
      "Epoch 36: 100%|██████████| 497/497 [00:21<00:00, 22.93it/s, v_num=.005, train_loss_step=2.350, val_loss=2.530, train_loss_epoch=2.370]\n",
      "\n",
      "Validation accuracy: 0.1464393138885498 (292/1994 correct)\n",
      "Validation loss (average): 2.505507469177246\n",
      "\n",
      "\n",
      "Epoch 36: 100%|██████████| 497/497 [00:23<00:00, 20.75it/s, v_num=.005, train_loss_step=2.350, val_loss=2.510, train_loss_epoch=2.340]\n",
      "\n",
      "Training accuracy: 0.18155546486377716 (1445/7959 correct)\n",
      "Training loss (average): 2.344397783279419\n",
      "\n",
      "\n",
      "Learning rate: [0.0003135167639754459] \n",
      "\n",
      "Epoch 37: 100%|██████████| 497/497 [00:21<00:00, 22.65it/s, v_num=.005, train_loss_step=2.530, val_loss=2.510, train_loss_epoch=2.340]\n",
      "\n",
      "Validation accuracy: 0.16700100898742676 (333/1994 correct)\n",
      "Validation loss (average): 2.4273831844329834\n",
      "\n",
      "\n",
      "Epoch 37: 100%|██████████| 497/497 [00:24<00:00, 20.53it/s, v_num=.005, train_loss_step=2.530, val_loss=2.430, train_loss_epoch=2.320]\n",
      "\n",
      "Training accuracy: 0.190476194024086 (1516/7959 correct)\n",
      "Training loss (average): 2.3218886852264404\n",
      "\n",
      "\n",
      "Learning rate: [0.0003056788448760597] \n",
      "\n",
      "Epoch 38: 100%|██████████| 497/497 [00:21<00:00, 23.24it/s, v_num=.005, train_loss_step=2.260, val_loss=2.430, train_loss_epoch=2.320]\n",
      "\n",
      "Validation accuracy: 0.15045134723186493 (300/1994 correct)\n",
      "Validation loss (average): 2.4181766510009766\n",
      "\n",
      "\n",
      "Epoch 38: 100%|██████████| 497/497 [00:23<00:00, 21.06it/s, v_num=.005, train_loss_step=2.260, val_loss=2.420, train_loss_epoch=2.300]\n",
      "\n",
      "Training accuracy: 0.19550195336341858 (1556/7959 correct)\n",
      "Training loss (average): 2.29889178276062\n",
      "\n",
      "\n",
      "Learning rate: [0.0002980368737541583] \n",
      "\n",
      "Epoch 39: 100%|██████████| 497/497 [00:22<00:00, 22.45it/s, v_num=.005, train_loss_step=2.120, val_loss=2.420, train_loss_epoch=2.300]\n",
      "\n",
      "Validation accuracy: 0.15697091817855835 (313/1994 correct)\n",
      "Validation loss (average): 2.4355344772338867\n",
      "\n",
      "\n",
      "Epoch 39: 100%|██████████| 497/497 [00:24<00:00, 20.43it/s, v_num=.005, train_loss_step=2.120, val_loss=2.440, train_loss_epoch=2.290]\n",
      "\n",
      "Training accuracy: 0.19236084818840027 (1531/7959 correct)\n",
      "Training loss (average): 2.293199300765991\n",
      "\n",
      "\n",
      "Learning rate: [0.00029058595191030427] \n",
      "\n",
      "Epoch 40: 100%|██████████| 497/497 [00:23<00:00, 21.55it/s, v_num=.005, train_loss_step=2.390, val_loss=2.440, train_loss_epoch=2.290]\n",
      "\n",
      "Validation accuracy: 0.13991975784301758 (279/1994 correct)\n",
      "Validation loss (average): 2.466092348098755\n",
      "\n",
      "\n",
      "Epoch 40: 100%|██████████| 497/497 [00:25<00:00, 19.56it/s, v_num=.005, train_loss_step=2.390, val_loss=2.470, train_loss_epoch=2.320]\n",
      "\n",
      "Training accuracy: 0.19035054743289948 (1515/7959 correct)\n",
      "Training loss (average): 2.3161001205444336\n",
      "\n",
      "\n",
      "Learning rate: [0.0002833213031125467] \n",
      "\n",
      "Epoch 41: 100%|██████████| 497/497 [00:23<00:00, 21.00it/s, v_num=.005, train_loss_step=2.200, val_loss=2.470, train_loss_epoch=2.320]\n",
      "\n",
      "Validation accuracy: 0.1725175529718399 (344/1994 correct)\n",
      "Validation loss (average): 2.3585362434387207\n",
      "\n",
      "\n",
      "Epoch 41: 100%|██████████| 497/497 [00:25<00:00, 19.16it/s, v_num=.005, train_loss_step=2.200, val_loss=2.360, train_loss_epoch=2.250]\n",
      "\n",
      "Training accuracy: 0.2078150510787964 (1654/7959 correct)\n",
      "Training loss (average): 2.2484021186828613\n",
      "\n",
      "\n",
      "Learning rate: [0.000276238270534733] \n",
      "\n",
      "Epoch 42: 100%|██████████| 497/497 [00:23<00:00, 21.45it/s, v_num=.005, train_loss_step=1.950, val_loss=2.360, train_loss_epoch=2.250]\n",
      "\n",
      "Validation accuracy: 0.16198596358299255 (323/1994 correct)\n",
      "Validation loss (average): 2.3833227157592773\n",
      "\n",
      "\n",
      "Epoch 42: 100%|██████████| 497/497 [00:25<00:00, 19.59it/s, v_num=.005, train_loss_step=1.950, val_loss=2.380, train_loss_epoch=2.240]\n",
      "\n",
      "Training accuracy: 0.21007664501667023 (1672/7959 correct)\n",
      "Training loss (average): 2.2443854808807373\n",
      "\n",
      "\n",
      "Learning rate: [0.0002693323137713647] \n",
      "\n",
      "Epoch 43: 100%|██████████| 497/497 [00:24<00:00, 19.97it/s, v_num=.005, train_loss_step=2.220, val_loss=2.380, train_loss_epoch=2.240]\n",
      "\n",
      "Validation accuracy: 0.16298896074295044 (325/1994 correct)\n",
      "Validation loss (average): 2.373603105545044\n",
      "\n",
      "\n",
      "Epoch 43: 100%|██████████| 497/497 [00:27<00:00, 18.28it/s, v_num=.005, train_loss_step=2.220, val_loss=2.370, train_loss_epoch=2.230]\n",
      "\n",
      "Training accuracy: 0.207438126206398 (1651/7959 correct)\n",
      "Training loss (average): 2.226100444793701\n",
      "\n",
      "\n",
      "Learning rate: [0.0002625990059270806] \n",
      "\n",
      "Epoch 44: 100%|██████████| 497/497 [00:22<00:00, 22.20it/s, v_num=.005, train_loss_step=2.330, val_loss=2.370, train_loss_epoch=2.230]\n",
      "\n",
      "Validation accuracy: 0.17201605439186096 (343/1994 correct)\n",
      "Validation loss (average): 2.3656158447265625\n",
      "\n",
      "\n",
      "Epoch 44: 100%|██████████| 497/497 [00:24<00:00, 20.17it/s, v_num=.005, train_loss_step=2.330, val_loss=2.370, train_loss_epoch=2.230]\n",
      "\n",
      "Training accuracy: 0.21007664501667023 (1672/7959 correct)\n",
      "Training loss (average): 2.2254269123077393\n",
      "\n",
      "\n",
      "Learning rate: [0.00025603403077890355] \n",
      "\n",
      "Epoch 45: 100%|██████████| 497/497 [00:24<00:00, 20.42it/s, v_num=.005, train_loss_step=2.240, val_loss=2.370, train_loss_epoch=2.230]\n",
      "\n",
      "Validation accuracy: 0.17552657425403595 (350/1994 correct)\n",
      "Validation loss (average): 2.3406546115875244\n",
      "\n",
      "\n",
      "Epoch 45: 100%|██████████| 497/497 [00:26<00:00, 18.63it/s, v_num=.005, train_loss_step=2.240, val_loss=2.340, train_loss_epoch=2.170]\n",
      "\n",
      "Training accuracy: 0.22151024639606476 (1763/7959 correct)\n",
      "Training loss (average): 2.1721606254577637\n",
      "\n",
      "\n",
      "Learning rate: [0.00024963318000943095] \n",
      "\n",
      "Epoch 46: 100%|██████████| 497/497 [00:25<00:00, 19.31it/s, v_num=.005, train_loss_step=2.560, val_loss=2.340, train_loss_epoch=2.170]\n",
      "\n",
      "Validation accuracy: 0.18054161965847015 (360/1994 correct)\n",
      "Validation loss (average): 2.35978102684021\n",
      "\n",
      "\n",
      "Epoch 46: 100%|██████████| 497/497 [00:28<00:00, 17.67it/s, v_num=.005, train_loss_step=2.560, val_loss=2.360, train_loss_epoch=2.170]\n",
      "\n",
      "Training accuracy: 0.21924865245819092 (1745/7959 correct)\n",
      "Training loss (average): 2.170778751373291\n",
      "\n",
      "\n",
      "Learning rate: [0.00024339235050919514] \n",
      "\n",
      "Epoch 47: 100%|██████████| 497/497 [00:23<00:00, 21.18it/s, v_num=.005, train_loss_step=2.090, val_loss=2.360, train_loss_epoch=2.170]\n",
      "\n",
      "Validation accuracy: 0.18054161965847015 (360/1994 correct)\n",
      "Validation loss (average): 2.280360221862793\n",
      "\n",
      "\n",
      "Epoch 47: 100%|██████████| 497/497 [00:26<00:00, 19.10it/s, v_num=.005, train_loss_step=2.090, val_loss=2.280, train_loss_epoch=2.150]\n",
      "\n",
      "Training accuracy: 0.23005402088165283 (1831/7959 correct)\n",
      "Training loss (average): 2.153214931488037\n",
      "\n",
      "\n",
      "Learning rate: [0.00023730754174646528] \n",
      "\n",
      "Epoch 48: 100%|██████████| 497/497 [00:24<00:00, 20.12it/s, v_num=.005, train_loss_step=1.990, val_loss=2.280, train_loss_epoch=2.150]\n",
      "\n",
      "Validation accuracy: 0.1564694046974182 (312/1994 correct)\n",
      "Validation loss (average): 2.364001512527466\n",
      "\n",
      "\n",
      "Epoch 48: 100%|██████████| 497/497 [00:27<00:00, 18.28it/s, v_num=.005, train_loss_step=1.990, val_loss=2.360, train_loss_epoch=2.140]\n",
      "\n",
      "Training accuracy: 0.2345772087574005 (1867/7959 correct)\n",
      "Training loss (average): 2.135314702987671\n",
      "\n",
      "\n",
      "Learning rate: [0.00023137485320280364] \n",
      "\n",
      "Epoch 49: 100%|██████████| 497/497 [00:26<00:00, 18.60it/s, v_num=.005, train_loss_step=1.820, val_loss=2.360, train_loss_epoch=2.140]\n",
      "\n",
      "Validation accuracy: 0.18204614520072937 (363/1994 correct)\n",
      "Validation loss (average): 2.3448047637939453\n",
      "\n",
      "\n",
      "Epoch 49: 100%|██████████| 497/497 [00:29<00:00, 16.99it/s, v_num=.005, train_loss_step=1.820, val_loss=2.340, train_loss_epoch=2.130]\n",
      "\n",
      "Training accuracy: 0.2370900809764862 (1887/7959 correct)\n",
      "Training loss (average): 2.1318271160125732\n",
      "\n",
      "\n",
      "Learning rate: [0.00022559048187273354] \n",
      "\n",
      "Epoch 50: 100%|██████████| 497/497 [00:28<00:00, 17.42it/s, v_num=.005, train_loss_step=2.180, val_loss=2.340, train_loss_epoch=2.130]\n",
      "\n",
      "Validation accuracy: 0.17452357709407806 (348/1994 correct)\n",
      "Validation loss (average): 2.3391575813293457\n",
      "\n",
      "\n",
      "Epoch 50: 100%|██████████| 497/497 [00:31<00:00, 15.92it/s, v_num=.005, train_loss_step=2.180, val_loss=2.340, train_loss_epoch=2.120]\n",
      "\n",
      "Training accuracy: 0.24073375761508942 (1916/7959 correct)\n",
      "Training loss (average): 2.1156108379364014\n",
      "\n",
      "\n",
      "Learning rate: [0.0002199507198259152] \n",
      "\n",
      "Epoch 51: 100%|██████████| 497/497 [00:27<00:00, 18.15it/s, v_num=.005, train_loss_step=1.910, val_loss=2.340, train_loss_epoch=2.120]\n",
      "\n",
      "Validation accuracy: 0.19157472252845764 (382/1994 correct)\n",
      "Validation loss (average): 2.2426774501800537\n",
      "\n",
      "\n",
      "Epoch 51: 100%|██████████| 497/497 [00:30<00:00, 16.56it/s, v_num=.005, train_loss_step=1.910, val_loss=2.240, train_loss_epoch=2.110]\n",
      "\n",
      "Training accuracy: 0.2427440583705902 (1932/7959 correct)\n",
      "Training loss (average): 2.1098580360412598\n",
      "\n",
      "\n",
      "Learning rate: [0.00021445195183026732] \n",
      "\n",
      "Epoch 52: 100%|██████████| 497/497 [00:27<00:00, 17.77it/s, v_num=.005, train_loss_step=2.070, val_loss=2.240, train_loss_epoch=2.110]\n",
      "\n",
      "Validation accuracy: 0.1775325983762741 (354/1994 correct)\n",
      "Validation loss (average): 2.309654951095581\n",
      "\n",
      "\n",
      "Epoch 52: 100%|██████████| 497/497 [00:30<00:00, 16.43it/s, v_num=.005, train_loss_step=2.070, val_loss=2.310, train_loss_epoch=2.090]\n",
      "\n",
      "Training accuracy: 0.2427440583705902 (1932/7959 correct)\n",
      "Training loss (average): 2.089083194732666\n",
      "\n",
      "\n",
      "Learning rate: [0.0002090906530345106] \n",
      "\n",
      "Epoch 53: 100%|██████████| 497/497 [00:23<00:00, 21.19it/s, v_num=.005, train_loss_step=1.880, val_loss=2.310, train_loss_epoch=2.090]\n",
      "\n",
      "Validation accuracy: 0.1960882693529129 (391/1994 correct)\n",
      "Validation loss (average): 2.265355110168457\n",
      "\n",
      "\n",
      "Epoch 53: 100%|██████████| 497/497 [00:25<00:00, 19.33it/s, v_num=.005, train_loss_step=1.880, val_loss=2.270, train_loss_epoch=2.070]\n",
      "\n",
      "Training accuracy: 0.2505339980125427 (1994/7959 correct)\n",
      "Training loss (average): 2.0666215419769287\n",
      "\n",
      "\n",
      "Learning rate: [0.00020386338670864786] \n",
      "\n",
      "Epoch 54: 100%|██████████| 497/497 [00:23<00:00, 21.18it/s, v_num=.005, train_loss_step=2.090, val_loss=2.270, train_loss_epoch=2.070]\n",
      "\n",
      "Validation accuracy: 0.17953862249851227 (358/1994 correct)\n",
      "Validation loss (average): 2.284235954284668\n",
      "\n",
      "\n",
      "Epoch 54: 100%|██████████| 497/497 [00:25<00:00, 19.29it/s, v_num=.005, train_loss_step=2.090, val_loss=2.280, train_loss_epoch=2.060]\n",
      "\n",
      "Training accuracy: 0.25932905077934265 (2064/7959 correct)\n",
      "Training loss (average): 2.0586612224578857\n",
      "\n",
      "\n",
      "Learning rate: [0.00019876680204093165] \n",
      "\n",
      "Epoch 55: 100%|██████████| 497/497 [00:25<00:00, 19.65it/s, v_num=.005, train_loss_step=2.170, val_loss=2.280, train_loss_epoch=2.060]\n",
      "\n",
      "Validation accuracy: 0.20812436938285828 (415/1994 correct)\n",
      "Validation loss (average): 2.2001514434814453\n",
      "\n",
      "\n",
      "Epoch 55: 100%|██████████| 497/497 [00:27<00:00, 17.94it/s, v_num=.005, train_loss_step=2.170, val_loss=2.200, train_loss_epoch=2.040]\n",
      "\n",
      "Training accuracy: 0.26234450936317444 (2088/7959 correct)\n",
      "Training loss (average): 2.0441112518310547\n",
      "\n",
      "\n",
      "Learning rate: [0.00019379763198990835] \n",
      "\n",
      "Epoch 56: 100%|██████████| 497/497 [00:27<00:00, 18.34it/s, v_num=.005, train_loss_step=1.760, val_loss=2.200, train_loss_epoch=2.040]\n",
      "\n",
      "Validation accuracy: 0.18204614520072937 (363/1994 correct)\n",
      "Validation loss (average): 2.2757511138916016\n",
      "\n",
      "\n",
      "Epoch 56: 100%|██████████| 497/497 [00:29<00:00, 16.90it/s, v_num=.005, train_loss_step=1.760, val_loss=2.280, train_loss_epoch=2.030]\n",
      "\n",
      "Training accuracy: 0.2702600955963135 (2151/7959 correct)\n",
      "Training loss (average): 2.026038885116577\n",
      "\n",
      "\n",
      "Learning rate: [0.00018895269119016062] \n",
      "\n",
      "Epoch 57: 100%|██████████| 497/497 [00:24<00:00, 20.66it/s, v_num=.005, train_loss_step=2.070, val_loss=2.280, train_loss_epoch=2.030]\n",
      "\n",
      "Validation accuracy: 0.19307923316955566 (385/1994 correct)\n",
      "Validation loss (average): 2.2448062896728516\n",
      "\n",
      "\n",
      "Epoch 57: 100%|██████████| 497/497 [00:26<00:00, 18.52it/s, v_num=.005, train_loss_step=2.070, val_loss=2.240, train_loss_epoch=2.020]\n",
      "\n",
      "Training accuracy: 0.2667420506477356 (2123/7959 correct)\n",
      "Training loss (average): 2.01938796043396\n",
      "\n",
      "\n",
      "Learning rate: [0.00018422887391040662] \n",
      "\n",
      "Epoch 58:  28%|██▊       | 138/497 [00:06<00:17, 20.84it/s, v_num=.005, train_loss_step=1.920, val_loss=2.240, train_loss_epoch=2.020]"
     ]
    }
   ],
   "source": [
    "version_num = 96\n",
    "epoch = 9\n",
    "step = 23920\n",
    "PATH = os.path.join(\n",
    "    root_path,\n",
    "    \"lightning_logs\",\n",
    "    \"version_\" + str(version_num),\n",
    "    \"checkpoints\",\n",
    "    \"epoch=\" + str(epoch) + \"-step=\" + str(step) + \".ckpt\",\n",
    ")\n",
    "\n",
    "model = FeatureExtractorNN()\n",
    "model.to(device)\n",
    "# model = FeatureExtractorNN.load_from_checkpoint(PATH)\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "logger = TensorBoardLogger(\n",
    "    \"/Users/ms/cs/ML/NeuroImagen/lightning_logs\",\n",
    "    name=\"Adam_1-e4*8_Lambda_0.975\",\n",
    "    version=\"weight_decay_0.005\",\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(max_epochs=200, callbacks=[lr_monitor], logger=logger)\n",
    "# trainer.fit(model,train_dataloaders=train_loader,val_dataloaders=val_loader,ckpt_path=PATH)\n",
    "trainer.validate(model, dataloaders=loaders[\"val\"])\n",
    "trainer.fit(model, train_dataloaders=loaders[\"train\"], val_dataloaders=loaders[\"val\"])\n",
    "# trainer.fit(model,train_dataloaders=train_loader)\n",
    "# trainer.validate(model, dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 124/124 [00:01<00:00, 108.29it/s]\n",
      "\n",
      "Validation accuracy: 0.2096288800239563 (418/1994 correct)\n",
      "Validation loss (average): 3.610106945037842\n",
      "\n",
      "\n",
      "Validation DataLoader 0: 100%|██████████| 124/124 [00:01<00:00, 107.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3.610106945037842     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.610106945037842    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 3.610106945037842}]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, dataloaders=loaders[\"val\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   1%|▏         | 1/76 [00:00<00:01, 61.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 76/76 [00:00<00:00, 89.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3.689608573913574     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.689608573913574    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 3.689608573913574, 'test_acc': 0.0}]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input and parameter tensors are not at the same device, found input tensor at cpu and parameter tensor at mps:0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb Cell 24\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# print(query.shape)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m query\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pred \u001b[39m=\u001b[39m model(query)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# print(pred)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(pred,dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# print(\"INPUT:\",input.shape)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m lstm_out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# tmp_out = lstm_out[:,-1,:] if input.dim()==3 else lstm_out[-1,:]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m tmp_out \u001b[39m=\u001b[39m lstm_out[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:]\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not at the same device, found input tensor at cpu and parameter tensor at mps:0"
     ]
    }
   ],
   "source": [
    "idx = 6\n",
    "query = val_dataset[idx][0].unsqueeze(dim=0)\n",
    "# print(query.shape)\n",
    "query.to(device)\n",
    "pred = model(query)\n",
    "# print(pred)\n",
    "pred = torch.argmax(pred, dim=1)\n",
    "# pred = pred.max(dim=1)\n",
    "# print(pred)\n",
    "print(\"predicted: \", id_to_name[lookup_dict[pred.item()]])\n",
    "print(\"answer: \", id_to_name[lookup_dict[val_dataset[idx][1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 64])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb Cell 27\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m x\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m y\u001b[39m=\u001b[39my\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m out \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y_hat \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# print(y==y_hat)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb Cell 27\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X33sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(tmp_out)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X33sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# print(\"out shape\",out.shape)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X33sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn(out)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X33sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifer(out)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X33sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    180\u001b[0m     bn_training,\n\u001b[1;32m    181\u001b[0m     exponential_average_factor,\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    183\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.10/site-packages/torch/nn/functional.py:2476\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2463\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2464\u001b[0m         batch_norm,\n\u001b[1;32m   2465\u001b[0m         (\u001b[39minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         eps\u001b[39m=\u001b[39meps,\n\u001b[1;32m   2474\u001b[0m     )\n\u001b[1;32m   2475\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[0;32m-> 2476\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msize())\n\u001b[1;32m   2478\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mbatch_norm(\n\u001b[1;32m   2479\u001b[0m     \u001b[39minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39mbackends\u001b[39m.\u001b[39mcudnn\u001b[39m.\u001b[39menabled\n\u001b[1;32m   2480\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.10/site-packages/torch/nn/functional.py:2444\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2442\u001b[0m     size_prods \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m size[i \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m]\n\u001b[1;32m   2443\u001b[0m \u001b[39mif\u001b[39;00m size_prods \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 2444\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 64])"
     ]
    }
   ],
   "source": [
    "# Calculate test accuracy\n",
    "num_correct = 0\n",
    "model.to(device)\n",
    "for x, y in test_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    out = model(x)\n",
    "    y_hat = out.argmax(dim=1)\n",
    "    # print(y==y_hat)\n",
    "    num_correct += (y == y_hat).sum()\n",
    "acc = num_correct / len(test_loader.dataset)\n",
    "print(\"Accuracy:\", acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='mps:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroimagen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
