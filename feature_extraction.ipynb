{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "import lightning as L\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lookup_dict import lookup_dict,id_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path=\"\"\n",
    "dataset_path = os.path.join(root_path,\"dataset\")\n",
    "images_dataset_path = os.path.join(dataset_path,\"imageNet_images\")\n",
    "eeg_dataset_path = os.path.join(dataset_path,\"eeg\")\n",
    "\n",
    "eeg_dataset_name = \"eeg_5_95_std.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- dataset load\n",
    "- dataset split\n",
    "- define model\n",
    "- add classifier\n",
    "- testing & accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge all image folders to create list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "dir_list = list(os.walk(images_dataset_path))\n",
    "# skip any unnecessary folders\n",
    "start_idx = len(dir_list)-40\n",
    "images_list = []\n",
    "for sub_dir in dir_list[start_idx:]:\n",
    "    # images_list+=sub_dir[2]\n",
    "    images_list.extend(sub_dir[2])\n",
    "    \n",
    "images_list = [image_name.replace(\".JPEG\",\"\") for image_name in images_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split images list to 8:1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(images_list)\n",
    "\n",
    "images_total_size = len(images_list)\n",
    "train_size = int(images_total_size*0.8)\n",
    "val_size = int(images_total_size*0.1)\n",
    "test_size = images_total_size-train_size-val_size\n",
    "\n",
    "train_images = images_list[:train_size]\n",
    "val_images = images_list[train_size:train_size+val_size]\n",
    "test_images = images_list[-1*test_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make train, val, test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,images_list) -> None:\n",
    "        super().__init__()\n",
    "        eeg_dataset = torch.load(os.path.join(eeg_dataset_path,eeg_dataset_name))\n",
    "        self.x_data = []\n",
    "        self.y_data = []\n",
    "        # self.y_data = [image_name.split(\"_\")[0] for image_name in images_list]\n",
    "        \n",
    "        for eeg_segment in eeg_dataset['dataset']:\n",
    "            for image_name in images_list:\n",
    "                if eeg_dataset['images'][eeg_segment['image']] == image_name:\n",
    "                    self.x_data.append(eeg_segment['eeg'][:,40:480])\n",
    "                    # all_channel_list = np.array(eeg_segment['eeg'])\n",
    "                    # self.x_data.append(torch.from_numpy(all_channel_list[:,40:480]))\n",
    "                    # self.x_data.append(torch.FloatTensor([eeg_sequence[40:480] for eeg_sequence in eeg_segment['eeg']]))\n",
    "                    class_id = image_name.split(\"_\")[0]\n",
    "                    self.y_data.append(lookup_dict[class_id])\n",
    "                    # self.y_data.append(eeg_dataset['labels'][eeg_segment['label']])\n",
    "                    break\n",
    "                                    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=[1,2,3,4,5]\n",
    "b[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6]]\n",
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
      "[[1, 2, 3], [4, 5, 6]]\n",
      "[[1, 2], [4, 5], [7, 8]]\n"
     ]
    }
   ],
   "source": [
    "a = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "print(np.array(a)[:2,:3].tolist())\n",
    "print(a)\n",
    "print(a[:2])\n",
    "print([inner[:2] for inner in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_images)\n",
    "val_dataset = CustomDataset(val_images)\n",
    "test_dataset = CustomDataset(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.5031, -0.5021, -0.4580,  ...,  0.4509,  0.3556,  0.2762],\n",
      "        [-0.6303, -0.6110, -0.5451,  ...,  0.1978,  0.0937,  0.0085],\n",
      "        [ 0.2163,  0.2300,  0.2122,  ...,  0.5433,  0.6652,  0.7695],\n",
      "        ...,\n",
      "        [ 0.1370,  0.1335,  0.0989,  ..., -0.0676, -0.1633, -0.2235],\n",
      "        [-0.0087, -0.0073, -0.0081,  ..., -0.0096, -0.0143, -0.0162],\n",
      "        [-0.0448, -0.0311, -0.0423,  ..., -0.1442, -0.2242, -0.2662]]), 37)\n",
      "torch.Size([128, 440])\n",
      "torch.Size([440])\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[0])\n",
    "print(test_dataset[0][0].shape)\n",
    "print(test_dataset[0][0][0].shape)\n",
    "print(type(test_dataset[0][0][0]))\n",
    "print(type(test_dataset[0][0]))\n",
    "print(type(test_dataset[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.5031, -0.5021, -0.4580,  ...,  0.4509,  0.3556,  0.2762],\n",
      "        [-0.6303, -0.6110, -0.5451,  ...,  0.1978,  0.0937,  0.0085],\n",
      "        [ 0.2163,  0.2300,  0.2122,  ...,  0.5433,  0.6652,  0.7695],\n",
      "        ...,\n",
      "        [ 0.1370,  0.1335,  0.0989,  ..., -0.0676, -0.1633, -0.2235],\n",
      "        [-0.0087, -0.0073, -0.0081,  ..., -0.0096, -0.0143, -0.0162],\n",
      "        [-0.0448, -0.0311, -0.0423,  ..., -0.1442, -0.2242, -0.2662]]), 37)\n",
      "torch.Size([128, 440])\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[0])\n",
    "print(test_dataset[0][0].shape)\n",
    "print(type(test_dataset[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.2970e-01, -2.0516e-01, -1.4497e-01,  ...,  1.7828e-04,\n",
      "          -6.1874e-02, -8.4426e-02],\n",
      "         [-2.3025e-01, -2.3465e-01, -1.9705e-01,  ...,  2.4091e-01,\n",
      "           1.6397e-01,  9.9622e-02],\n",
      "         [ 3.7623e-01,  3.9733e-01,  3.5205e-01,  ..., -1.2053e-01,\n",
      "          -3.9394e-02,  6.2158e-03],\n",
      "         ...,\n",
      "         [ 3.5077e-02,  1.9111e-02, -4.2109e-02,  ...,  4.0012e-02,\n",
      "           5.4250e-02,  4.5684e-02],\n",
      "         [ 1.7042e-02,  1.5713e-02,  9.6448e-03,  ..., -1.0437e-02,\n",
      "          -9.6514e-03, -8.0307e-03],\n",
      "         [-5.6605e-02, -3.8338e-02, -4.0459e-02,  ...,  7.1151e-02,\n",
      "           6.2956e-02,  5.1401e-02]]])\n",
      "torch.Size([1, 128, 440])\n",
      "tensor([14])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# train_loader = DataLoader(train_dataset,shuffle=True,num_workers=1)\n",
    "train_loader = DataLoader(train_dataset,shuffle=True,batch_size=16)\n",
    "# val_loader = DataLoader(val_dataset,num_workers=1,persistent_workers=True)\n",
    "val_loader = DataLoader(val_dataset)\n",
    "test_loader = DataLoader(test_dataset)\n",
    "\n",
    "example = next(iter(val_loader))\n",
    "print(example[0])\n",
    "print(example[0].shape)\n",
    "print(example[1])\n",
    "print(type(example[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with classifier attached\n",
    "class FeatureExtractorNN(L.LightningModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # self.lstm = nn.LSTM(input_size=128,hidden_size=128,num_layers=128)\n",
    "        self.lstm = nn.LSTM(input_size=128,hidden_size=128,num_layers=1,batch_first=True)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(in_features=128,out_features=128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifer=nn.Sequential(\n",
    "            nn.Linear(in_features=128,out_features=40),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.training_step_outputs = {\"correct_num\":0,\"loss_sum\":0}\n",
    "    \n",
    "    def forward(self,input):\n",
    "        # print(\"\\nINPUT\")\n",
    "        # print(input.shape)\n",
    "        # print(input.shape)\n",
    "        # input = input.transpose(1,2) if input.dim()==3 else input.transpose(0,1)\n",
    "        input = input.transpose(1,2)\n",
    "        # print(\"INPUT:\",input.shape)\n",
    "        lstm_out, _ = self.lstm(input)\n",
    "        # tmp_out = lstm_out[:,-1,:] if input.dim()==3 else lstm_out[-1,:]\n",
    "        tmp_out = lstm_out[:,-1,:]\n",
    "        out = self.output(tmp_out)\n",
    "        # print(\"out shape\",out.shape)\n",
    "        res = self.classifer(out)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters())\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        # print(\"\\nbatch:\",batch)\n",
    "        # print(\"batch shape:\",batch[0].shape)\n",
    "        x,y = batch\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        # print(\"\\nx:\",x)\n",
    "        # print(\"x shape:\",x.shape)\n",
    "        # print(\"\\nLABEL\")\n",
    "        # print(x)\n",
    "        # print(x.shape)\n",
    "        # print(type(x))\n",
    "        out = self(x)\n",
    "        # print(x)\n",
    "        # print(x[0])\n",
    "        # print(x.shape)\n",
    "        # print(\"\\noutput: \",out)\n",
    "        # print(\"output shape: \",out.shape)\n",
    "        # print(\"\\nlabel: \",y)\n",
    "        loss = self.loss_fn(out,y)\n",
    "        # print(\"\\nloss: \",loss)\n",
    "        # print(\"loss shape: \",loss.shape)\n",
    "        \n",
    "        self.log_dict({\"train_loss\":loss},prog_bar=True,on_epoch=True)\n",
    "        # print(\"   ||   training loss:\", loss.item())\n",
    "        preds = out.argmax(dim=1)\n",
    "        self.training_step_outputs['correct_num']+=(preds==y).sum()\n",
    "        self.training_step_outputs['loss_sum']+=loss\n",
    "        # self.training_step_outputs.append(torch.cat((preds==y).sum(),loss),dim=0)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        num_correct = self.training_step_outputs['correct_num']\n",
    "        acc = num_correct/len(train_dataset)\n",
    "        loss = self.training_step_outputs['loss_sum']/len(train_loader)\n",
    "        print(\"EPOCH:\",self.current_epoch)\n",
    "        print(\"Training accuracy:\",acc.item(),\" (\"+str(num_correct.item())+\" correct)\")\n",
    "        print(\"Training loss (average):\",loss.item())\n",
    "        self.training_step_outputs['correct_num']=0\n",
    "        self.training_step_outputs['loss_sum']=0\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out,y)\n",
    "\n",
    "        self.log_dict({\"val_loss\":loss},prog_bar=True,on_epoch=True)\n",
    "        # print(\"   ||   validation loss:\", loss.item())\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        \n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out,y)\n",
    "        \n",
    "        y_hat = torch.argmax(out,dim=1)\n",
    "        # print(\"OUT,YHAT:\",out,y_hat)\n",
    "        test_acc = torch.sum(y == y_hat).item() / (len(y) * 1.0)\n",
    "        \n",
    "        self.log_dict({'test_loss': loss, 'test_acc': test_acc},prog_bar=True,on_epoch=True)\n",
    "        # print(\"   ||   test loss:\",loss.item(), \"   ||   test accuracy:\",test_acc )\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3,0,0,0],[1,2,0,5,3,4]])\n",
    "b = torch.tensor([2,3])\n",
    "(a.argmax(dim=1) == b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/ms/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | lstm      | LSTM             | 132 K \n",
      "1 | output    | Sequential       | 16.5 K\n",
      "2 | classifer | Sequential       | 5.2 K \n",
      "3 | loss_fn   | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "153 K     Trainable params\n",
      "0         Non-trainable params\n",
      "153 K     Total params\n",
      "0.615     Total estimated model params size (MB)\n",
      "/Users/ms/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aec992f8e2a4d8e964c30a63acc1f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "version_num= 96\n",
    "epoch = 9\n",
    "step = 23920\n",
    "PATH = os.path.join(root_path,\"lightning_logs\",\"version_\"+str(version_num),\"checkpoints\",\"epoch=\"+str(epoch)+\"-step=\"+str(step)+\".ckpt\")\n",
    "\n",
    "model = FeatureExtractorNN()\n",
    "model.to(device)\n",
    "# model = FeatureExtractorNN.load_from_checkpoint(PATH)\n",
    "\n",
    "# outputs = model(train_dataset[0][0])\n",
    "# print(outputs)\n",
    "\n",
    "trainer = L.Trainer(max_epochs=10)\n",
    "# trainer.fit(model,train_dataloaders=train_loader,val_dataloaders=val_loader,ckpt_path=PATH)\n",
    "# trainer.fit(model,train_dataloaders=train_loader,val_dataloaders=val_loader)\n",
    "trainer.fit(model,train_dataloaders=train_loader)\n",
    "# trainer.validate(model, dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.test(model,dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input and parameter tensors are not at the same device, found input tensor at cpu and parameter tensor at mps:0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb Cell 24\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# print(query.shape)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m query\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pred \u001b[39m=\u001b[39m model(query)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# print(pred)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(pred,dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# print(\"INPUT:\",input.shape)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m lstm_out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# tmp_out = lstm_out[:,-1,:] if input.dim()==3 else lstm_out[-1,:]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X32sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m tmp_out \u001b[39m=\u001b[39m lstm_out[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:]\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not at the same device, found input tensor at cpu and parameter tensor at mps:0"
     ]
    }
   ],
   "source": [
    "idx = 6\n",
    "query = val_dataset[idx][0].unsqueeze(dim=0)\n",
    "# print(query.shape)\n",
    "query.to(device)\n",
    "pred = model(query)\n",
    "# print(pred)\n",
    "pred = torch.argmax(pred,dim=1)\n",
    "# pred = pred.max(dim=1)\n",
    "# print(pred)\n",
    "print(\"predicted: \",id_to_name[lookup_dict[pred.item()]])\n",
    "print(\"answer: \",id_to_name[lookup_dict[val_dataset[idx][1]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a4ba067024453eb3f836c4b9e2a7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1206 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n",
      "tensor([False], device='mps:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb Cell 25\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     out \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     y_hat \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mprint\u001b[39m(y\u001b[39m==\u001b[39my_hat)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     num_correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (y\u001b[39m==\u001b[39my_hat)\u001b[39m.\u001b[39msum()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ms/cs/ML/NeuroImagen/feature_extraction.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m acc \u001b[39m=\u001b[39m num_correct\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(test_loader\u001b[39m.\u001b[39mdataset)\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/torch/_tensor.py:431\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    428\u001b[0m         Tensor\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, tensor_contents\u001b[39m=\u001b[39mtensor_contents\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[39m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_tensor_str\u001b[39m.\u001b[39;49m_str(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/torch/_tensor_str.py:664\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(), torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39m_python_dispatch\u001b[39m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    663\u001b[0m     guard \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 664\u001b[0m     \u001b[39mreturn\u001b[39;00m _str_intern(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/torch/_tensor_str.py:595\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    594\u001b[0m                 \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 595\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39;49m, indent)\n\u001b[1;32m    597\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mstrided:\n\u001b[1;32m    598\u001b[0m     suffixes\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mlayout=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/torch/_tensor_str.py:347\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    344\u001b[0m         \u001b[39mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    345\u001b[0m     )\n\u001b[1;32m    346\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     formatter \u001b[39m=\u001b[39m _Formatter(get_summarized_data(\u001b[39mself\u001b[39;49m) \u001b[39mif\u001b[39;49;00m summarize \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    348\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[39mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/torch/_tensor_str.py:133\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfloating_dtype:\n\u001b[1;32m    132\u001b[0m     \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m tensor_view:\n\u001b[0;32m--> 133\u001b[0m         value_str \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mlen\u001b[39m(value_str))\n\u001b[1;32m    136\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/neuroimagen/lib/python3.11/site-packages/torch/_tensor.py:933\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, format_spec)\n\u001b[1;32m    932\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_meta \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39mis\u001b[39;00m Tensor:\n\u001b[0;32m--> 933\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitem()\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m(format_spec)\n\u001b[1;32m    934\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m(\u001b[39mself\u001b[39m, format_spec)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calculate test accuracy\n",
    "num_correct = 0\n",
    "for x,y in tqdm(test_loader):\n",
    "    x=x.to(device)\n",
    "    y=y.to(device)\n",
    "    out = model(x)\n",
    "    y_hat = out.argmax(dim=1)\n",
    "    # print(y==y_hat)\n",
    "    num_correct += (y==y_hat).sum()\n",
    "acc = num_correct/len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='mps:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroimagen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
