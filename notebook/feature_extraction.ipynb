{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), \"code\"))\n",
    "import dataset as D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/home/choi/BrainDecoder/\"\n",
    "dataset_path = os.path.join(root_path, \"dataset\")\n",
    "images_dataset_path = os.path.join(dataset_path, \"imageNet_images\")\n",
    "eeg_dataset_path = os.path.join(dataset_path, \"eeg\")\n",
    "\n",
    "config = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset_1 (using custom dataset method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all image folders to create list of images\n",
    "\n",
    "import random\n",
    "\n",
    "dir_list = list(os.walk(images_dataset_path))\n",
    "# skip any unnecessary folders\n",
    "start_idx = len(dir_list) - 40\n",
    "images_list = []\n",
    "for sub_dir in dir_list[start_idx:]:\n",
    "    # images_list+=sub_dir[2]\n",
    "    images_list.extend(sub_dir[2])\n",
    "\n",
    "images_list = [image_name.replace(\".JPEG\", \"\") for image_name in images_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split images list to 8:1:1\n",
    "\n",
    "# random.shuffle(images_list)\n",
    "\n",
    "images_total_size = len(images_list)\n",
    "train_size = int(images_total_size * 0.8)\n",
    "val_size = int(images_total_size * 0.1)\n",
    "test_size = images_total_size - train_size - val_size\n",
    "\n",
    "train_images = images_list[:train_size]\n",
    "val_images = images_list[train_size : train_size + val_size]\n",
    "test_images = images_list[-1 * test_size :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_dataset_name = \"eeg_5_95_std.pth\"\n",
    "eeg_dataset = torch.load(os.path.join(eeg_dataset_path, eeg_dataset_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_list) -> None:\n",
    "        super().__init__()\n",
    "        self.x_data = []\n",
    "        self.y_data = []\n",
    "        # self.y_data = [image_name.split(\"_\")[0] for image_name in images_list]\n",
    "\n",
    "        for eeg_segment in eeg_dataset[\"dataset\"]:\n",
    "            for image_name in images_list:\n",
    "                if eeg_dataset[\"images\"][eeg_segment[\"image\"]] == image_name:\n",
    "                    self.x_data.append(eeg_segment[\"eeg\"][:, 20:460])\n",
    "                    # all_channel_list = np.array(eeg_segment['eeg'])\n",
    "                    # self.x_data.append(torch.from_numpy(all_channel_list[:,40:480]))\n",
    "                    # self.x_data.append(torch.FloatTensor([eeg_sequence[40:480] for eeg_sequence in eeg_segment['eeg']]))\n",
    "                    class_id = image_name.split(\"_\")[0]\n",
    "                    self.y_data.append(lookup_dict[class_id])\n",
    "                    # self.y_data.append(eeg_dataset['labels'][eeg_segment['label']])\n",
    "                    break\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_images)\n",
    "val_dataset = CustomDataset(val_images)\n",
    "test_dataset = CustomDataset(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset_2 (using splitter method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, eeg_dataset_file_name=\"eeg_5_95_std.pth\") -> None:\n",
    "        super().__init__()\n",
    "        loaded = torch.load(os.path.join(eeg_dataset_path, eeg_dataset_file_name))\n",
    "        self.data = loaded[\"dataset\"]\n",
    "        self.labels = loaded[\"labels\"]\n",
    "        self.images = loaded[\"images\"]\n",
    "        self.size = len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # t() -> transpose\n",
    "        eeg = self.data[idx][\"eeg\"].t().to(torch.float)\n",
    "        eeg = eeg[20:460, :]\n",
    "\n",
    "        label = self.data[idx][\"label\"]\n",
    "        return eeg, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Splitter(Dataset):\n",
    "    def __init__(self, dataset, split_name=\"train\") -> None:\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "        loaded = torch.load(\n",
    "            os.path.join(eeg_dataset_path, \"block_splits_by_image_all.pth\")\n",
    "        )\n",
    "        self.target_data_indices = loaded[\"splits\"][0][split_name]\n",
    "        # filter data that is too short\n",
    "        self.target_data_indices = [\n",
    "            i\n",
    "            for i in self.target_data_indices\n",
    "            if 450 <= self.dataset.data[i][\"eeg\"].size(1) <= 600\n",
    "        ]\n",
    "\n",
    "        self.size = len(self.target_data_indices)\n",
    "        self.all_labels = np.array(self.get_all_labels())\n",
    "        self.all_eegs = self.get_all_eegs()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg, label = self.dataset[self.target_data_indices[idx]]\n",
    "        return eeg, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def get_all_labels(self):\n",
    "        data = [self.dataset[idx] for idx in self.target_data_indices]\n",
    "        return [item[1] for item in data]\n",
    "\n",
    "    def get_all_eegs(self):\n",
    "        data = [self.dataset[idx] for idx in self.target_data_indices]\n",
    "        return [item[0] for item in data]\n",
    "\n",
    "    def generate_data_points(self, anchor_labels, positive=True):\n",
    "        eeg_shape = self.__getitem__(0)[0].size()\n",
    "        eegs = torch.empty(0, eeg_shape[0], eeg_shape[1])\n",
    "        labels = torch.empty(0)\n",
    "        for anchor_label in anchor_labels:\n",
    "            indices = (\n",
    "                np.argwhere(self.all_labels == anchor_label.item())[:, 0]\n",
    "                if positive\n",
    "                else np.argwhere(self.all_labels != anchor_label.item())[:, 0]\n",
    "            )\n",
    "            data_idx = np.random.choice(indices)\n",
    "            eeg = self.all_eegs[data_idx]\n",
    "            eegs = torch.cat((eegs, eeg.unsqueeze(dim=0)))\n",
    "            labels = torch.cat(\n",
    "                (labels, torch.tensor(self.all_labels[data_idx]).unsqueeze(dim=0))\n",
    "            )\n",
    "\n",
    "        return eegs, labels\n",
    "\n",
    "    def get_data(self, anchor_label, positive: bool = True):\n",
    "        cnt = 0\n",
    "        while True:\n",
    "            idx = random.choice(self.target_data_indices)\n",
    "            if positive and self.dataset[idx][1] == anchor_label:\n",
    "                return self.dataset[idx]\n",
    "            if not positive and self.dataset[idx][1] != anchor_label:\n",
    "                return self.dataset[idx]\n",
    "\n",
    "            if cnt >= 2000:\n",
    "                raise Exception(f\"get_data failed after {cnt} tries\")\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EEGDataset(eeg_dataset_file_name=\"eeg_signals_raw_with_mean_std.pth\")\n",
    "loaders = {\n",
    "    split: DataLoader(\n",
    "        Splitter(dataset, split_name=split),\n",
    "        batch_size=config[\"batch-size\"],\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=1,\n",
    "    )\n",
    "    for split in [\"train\", \"val\", \"test\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset 3 import from py file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = D.EEGDataset(eeg_dataset_file_name=\"eeg_signals_raw_with_mean_std.pth\")\n",
    "\n",
    "loaders = {\n",
    "    split: DataLoader(\n",
    "        D.Splitter(dataset, split_name=split),\n",
    "        batch_size=config[\"batch-size\"],\n",
    "        shuffle=True if split == \"train\" else False,\n",
    "        num_workers=23,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    for split in [\"train\", \"val\", \"test\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "gpu_id = 2\n",
    "device = f\"cuda:{gpu_id}\" if torch.cuda.is_available else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "seed = 1563423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with classifier attached\n",
    "class FeatureExtractorNN(L.LightningModule):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # seed_everything(seed,workers=True)\n",
    "\n",
    "        self.input_size = 128\n",
    "        self.hidden_size = 128\n",
    "        self.lstm_layers = config[\"lstm-layer\"]\n",
    "        self.out_size = 128\n",
    "\n",
    "        # self.lstm = nn.LSTM(input_size=128,hidden_size=128,num_layers=128)\n",
    "        self.lstm = nn.LSTM(\n",
    "            self.input_size,\n",
    "            self.hidden_size,\n",
    "            num_layers=self.lstm_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(in_features=self.hidden_size, out_features=self.out_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.classifer = nn.Sequential(\n",
    "            nn.Linear(in_features=self.out_size, out_features=40),\n",
    "            # don't use softmax with cross entropy loss\n",
    "            # nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        # self.loss_fn = nn.NLLLoss()\n",
    "        self.training_step_outputs = {\"correct_num\": 0, \"loss_sum\": 0}\n",
    "        self.validation_step_outputs = {\"correct_num\": 0, \"loss_sum\": 0}\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        lstm_init = (\n",
    "            torch.zeros(self.lstm_layers, batch_size, self.hidden_size),\n",
    "            torch.zeros(self.lstm_layers, batch_size, self.hidden_size),\n",
    "        )\n",
    "        lstm_init = (lstm_init[0].to(device), lstm_init[0].to(device))\n",
    "\n",
    "        # dont need to transpose because already transposed when creating dataset\n",
    "        # input = input.transpose(1,2)\n",
    "\n",
    "        lstm_out, _ = self.lstm(input, lstm_init)\n",
    "        # tmp_out = lstm_out[:,-1,:] if input.dim()==3 else lstm_out[-1,:]\n",
    "        tmp_out = lstm_out[:, -1, :]\n",
    "        out = self.output(tmp_out)\n",
    "        # print(\"out shape\",out.shape)\n",
    "        res = self.classifer(out)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out, y)\n",
    "\n",
    "        self.log_dict({\"train_loss\": loss}, prog_bar=True, on_epoch=True)\n",
    "        preds = out.argmax(dim=1)\n",
    "        self.training_step_outputs[\"correct_num\"] += (preds == y).sum()\n",
    "        self.training_step_outputs[\"loss_sum\"] += loss\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        num_correct = self.training_step_outputs[\"correct_num\"]\n",
    "        acc = num_correct / loaders[\"train\"].dataset.__len__()\n",
    "        loss = self.training_step_outputs[\"loss_sum\"] / loaders[\"train\"].__len__()\n",
    "        print(\"\\n\")\n",
    "        # print(\"EPOCH:\",self.current_epoch)\n",
    "        print(\n",
    "            f\"Training accuracy: {acc.item()} ({num_correct.item()}/{loaders['train'].dataset.__len__()} correct)\"\n",
    "        )\n",
    "        print(\"Training loss (average):\", loss.item())\n",
    "        # print(\"\\n\")\n",
    "        self.training_step_outputs[\"correct_num\"] = 0\n",
    "        self.training_step_outputs[\"loss_sum\"] = 0\n",
    "\n",
    "        print(\"Learning rate:\", self.scheduler.get_last_lr(), \"\\n\")\n",
    "\n",
    "        self.log_dict({\"train_acc_epoch\": acc.item()})\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out, y)\n",
    "\n",
    "        self.log_dict({\"val_loss\": loss}, prog_bar=True, on_epoch=True)\n",
    "        preds = out.argmax(dim=1)\n",
    "        self.validation_step_outputs[\"correct_num\"] += (preds == y).sum()\n",
    "        self.validation_step_outputs[\"loss_sum\"] += loss\n",
    "        # return loss\n",
    "\n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        num_correct = self.validation_step_outputs[\"correct_num\"]\n",
    "        acc = num_correct / loaders[\"val\"].dataset.__len__()\n",
    "        loss = self.validation_step_outputs[\"loss_sum\"] / loaders[\"val\"].__len__()\n",
    "        print(\"\\n\")\n",
    "        # print(\"EPOCH:\",self.current_epoch)\n",
    "        print(\n",
    "            f\"Validation accuracy: {acc.item()} ({num_correct.item()}/{loaders['val'].dataset.__len__()} correct)\"\n",
    "        )\n",
    "        print(\"Validation loss (average):\", loss.item())\n",
    "        print(\"\\n\")\n",
    "        self.validation_step_outputs[\"correct_num\"] = 0\n",
    "        self.validation_step_outputs[\"loss_sum\"] = 0\n",
    "        self.log_dict({\"val_acc_epoch\": acc.item()})\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "\n",
    "        out = self(x)\n",
    "        loss = self.loss_fn(out, y)\n",
    "\n",
    "        y_hat = torch.argmax(out, dim=1)\n",
    "        # print(\"OUT,YHAT:\",out,y_hat)\n",
    "        test_acc = torch.sum(y == y_hat).item() / (len(y) * 1.0)\n",
    "\n",
    "        self.log_dict(\n",
    "            {\"test_loss\": loss, \"test_acc\": test_acc}, prog_bar=True, on_epoch=True\n",
    "        )\n",
    "        # print(\"   ||   test loss:\",loss.item(), \"   ||   test accuracy:\",test_acc )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=config[\"lr\"],\n",
    "            weight_decay=config[\"weight-decay\"],\n",
    "            betas=config[\"betas\"],\n",
    "        )\n",
    "        # scheduler = optim.lr_scheduler.LambdaLR(\n",
    "        #     optimizer, lambda epoch: config[\"lambda-factor\"] ** epoch\n",
    "        # )\n",
    "        scheduler = optim.lr_scheduler.CyclicLR(\n",
    "            optimizer,\n",
    "            base_lr=1e-5,\n",
    "            max_lr=1e-2,\n",
    "            step_size_up=1000,\n",
    "            step_size_down=None,\n",
    "            mode=\"exp_range\",\n",
    "            gamma=0.995,\n",
    "            cycle_momentum=False,\n",
    "        )\n",
    "        self.scheduler = scheduler\n",
    "        return [optimizer], [scheduler]\n",
    "        # return [optimizer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch-size\": 16,\n",
    "    \"optimizer\": \"Adam\",  # (\"Adam\", \"AdamW\", \"SGD\")\n",
    "    \"lr\": 1e-3,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    # \"scheduler\": \"LambdaLR\",\n",
    "    \"scheduler\": \"CyclicLR\",\n",
    "    \"lambda-factor\": 0.95,\n",
    "    \"weight-decay\": 0.001,\n",
    "    \"lstm-layer\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | lstm      | LSTM             | 396 K \n",
      "1 | output    | Sequential       | 16.5 K\n",
      "2 | classifer | Sequential       | 5.2 K \n",
      "3 | loss_fn   | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "417 K     Trainable params\n",
      "0         Non-trainable params\n",
      "417 K     Total params\n",
      "1.672     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choi/Downloads/miniconda3/envs/braindecoder/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  7.71it/s]\n",
      "\n",
      "Validation accuracy: 0.0 (0/1994 correct)\n",
      "Validation loss (average): 0.059094130992889404\n",
      "\n",
      "\n",
      "Epoch 0: 100%|██████████| 498/498 [00:09<00:00, 53.76it/s, v_num=9:37, train_loss_step=3.670]\n",
      "\n",
      "Validation accuracy: 0.020060181617736816 (40/1994 correct)\n",
      "Validation loss (average): 3.69327449798584\n",
      "\n",
      "\n",
      "Epoch 0: 100%|██████████| 498/498 [00:14<00:00, 33.54it/s, v_num=9:37, train_loss_step=3.670, val_loss=3.690, train_loss_epoch=3.690]\n",
      "\n",
      "Training accuracy: 0.02965196780860424 (236/7959 correct)\n",
      "Training loss (average): 3.688868522644043\n",
      "Learning rate: [1.9940049999998908e-05] \n",
      "\n",
      "Epoch 1: 100%|██████████| 498/498 [00:13<00:00, 37.45it/s, v_num=9:37, train_loss_step=3.690, val_loss=3.690, train_loss_epoch=3.690]\n",
      "\n",
      "Validation accuracy: 0.02306920848786831 (46/1994 correct)\n",
      "Validation loss (average): 3.6927762031555176\n",
      "\n",
      "\n",
      "Epoch 1: 100%|██████████| 498/498 [00:18<00:00, 26.44it/s, v_num=9:37, train_loss_step=3.690, val_loss=3.690, train_loss_epoch=3.690]\n",
      "\n",
      "Training accuracy: 0.0337982177734375 (269/7959 correct)\n",
      "Training loss (average): 3.6876769065856934\n",
      "Learning rate: [2.9780699499997824e-05] \n",
      "\n",
      "Epoch 2:  57%|█████▋    | 282/498 [00:09<00:07, 29.67it/s, v_num=9:37, train_loss_step=3.690, val_loss=3.690, train_loss_epoch=3.690]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choi/Downloads/miniconda3/envs/braindecoder/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "model = FeatureExtractorNN()\n",
    "# model = FeatureExtractorNN.load_from_checkpoint(PATH)\n",
    "model.to(device)\n",
    "\n",
    "now = datetime.now(tz=timezone(\"Asia/Tokyo\"))\n",
    "now_time = now.strftime(\"%H:%M\")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "logger = TensorBoardLogger(\n",
    "    \"/home/choi/BrainDecoder/lightning_logs/FeatureExtractionClassification\",\n",
    "    name=f\"{now_time}_{config['optimizer']}_{config['lr']}_{config['scheduler']}_weight-decay_{config['weight-decay']}_lambda-factor_{config['lambda-factor']}\",\n",
    "    version=now.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=500,\n",
    "    callbacks=[lr_monitor],\n",
    "    logger=logger,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[gpu_id],\n",
    ")\n",
    "trainer.fit(model, train_dataloaders=loaders[\"train\"], val_dataloaders=loaders[\"val\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ms/anaconda3/envs/braindecoder/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:492: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/Users/ms/anaconda3/envs/braindecoder/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 125/125 [00:03<00:00, 32.05it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ms/anaconda3/envs/braindecoder/lib/python3.10/site-packages/lightning/pytorch/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.01308505330234766    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    3.7041985988616943     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.01308505330234766   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   3.7041985988616943    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 3.7041985988616943, 'test_acc': 0.01308505330234766}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, dataloaders=loaders[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 6\n",
    "# query = val_dataset[idx][0].unsqueeze(dim=0)\n",
    "# # print(query.shape)\n",
    "# query.to(device)\n",
    "# pred = model(query)\n",
    "# # print(pred)\n",
    "# pred = torch.argmax(pred, dim=1)\n",
    "# # pred = pred.max(dim=1)\n",
    "# # print(pred)\n",
    "# print(\"predicted: \", id_to_name[lookup_dict[pred.item()]])\n",
    "# print(\"answer: \", id_to_name[lookup_dict[val_dataset[idx][1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate test accuracy\n",
    "# num_correct = 0\n",
    "# model.to(device)\n",
    "# for x, y in test_loader:\n",
    "#     x = x.to(device)\n",
    "#     y = y.to(device)\n",
    "#     out = model(x)\n",
    "#     y_hat = out.argmax(dim=1)\n",
    "#     # print(y==y_hat)\n",
    "#     num_correct += (y == y_hat).sum()\n",
    "# acc = num_correct / len(test_loader.dataset)\n",
    "# print(\"Accuracy:\", acc.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroimagen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
